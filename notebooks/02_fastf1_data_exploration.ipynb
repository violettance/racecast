{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèéÔ∏è FastF1 Data Exploration & Telemetry Analysis\n",
        "\n",
        "## Overview\n",
        "This notebook explores advanced F1 telemetry and strategy data using the FastF1 API to enrich our existing Ergast dataset (2017-2025).\n",
        "\n",
        "### Data Enhancement Strategy\n",
        "- **Ergast Coverage**: 2017-2025 (complete historical data)\n",
        "- **FastF1 Coverage**: 2018-2025 (telemetry & advanced features)\n",
        "- **2017 Data**: Will rely solely on Ergast features\n",
        "- **2018-2025**: Enhanced with FastF1 telemetry, tire strategy, and weather data\n",
        "\n",
        "### Target Features to Add\n",
        "1. **Telemetry**: Sector times, speed data, throttle/brake patterns\n",
        "2. **Strategy**: Tire compounds, pit stop timing, fuel strategy\n",
        "3. **Weather**: Track conditions, temperature, rain probability\n",
        "4. **Track**: Session-specific performance metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Raw data directory: ../data/raw\n",
            "üìÅ Processed data directory: ../data/processed\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "# Data paths\n",
        "RAW_DATA_DIR = Path('../data/raw')\n",
        "PROCESSED_DATA_DIR = Path('../data/processed')\n",
        "print(f\"üìÅ Raw data directory: {RAW_DATA_DIR}\")\n",
        "print(f\"üìÅ Processed data directory: {PROCESSED_DATA_DIR}\")\n",
        "\n",
        "# Plotly theme\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_white\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ FastF1 Installation & Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ FastF1 already installed - Version: 3.6.1\n",
            "üóÇÔ∏è Cache enabled at: ../data/cache\n"
          ]
        }
      ],
      "source": [
        "# Install fastf1 if not already installed\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    import fastf1\n",
        "    print(f\"‚úÖ FastF1 already installed - Version: {fastf1.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"üì¶ Installing FastF1...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"fastf1\"])\n",
        "    import fastf1\n",
        "    print(f\"‚úÖ FastF1 installed successfully - Version: {fastf1.__version__}\")\n",
        "\n",
        "# Enable cache for better performance\n",
        "cache_dir = Path('../data/cache')\n",
        "cache_dir.mkdir(exist_ok=True)\n",
        "fastf1.Cache.enable_cache(str(cache_dir))\n",
        "print(f\"üóÇÔ∏è Cache enabled at: {cache_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç FastF1 Coverage Analysis (2017-2025)\n",
        "\n",
        "Let's check what data is available for our target time range.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Testing FastF1 data coverage for 2017-2025:\n",
            "============================================================\n",
            "2017: ‚úÖ Available - 20 races (First: Australian Grand Prix)\n",
            "2018: ‚úÖ Available - 21 races (First: Australian Grand Prix)\n",
            "2019: ‚úÖ Available - 21 races (First: Australian Grand Prix)\n",
            "2020: ‚úÖ Available - 19 races (First: Pre-Season Test 1)\n",
            "2021: ‚úÖ Available - 23 races (First: Pre-Season Test)\n",
            "2022: ‚úÖ Available - 24 races (First: Pre-Season Track Session)\n",
            "2023: ‚úÖ Available - 23 races (First: Pre-Season Testing)\n",
            "2024: ‚úÖ Available - 25 races (First: Pre-Season Testing)\n",
            "2025: ‚úÖ Available - 25 races (First: Pre-Season Testing)\n",
            "\n",
            "üìä Coverage Summary:\n",
            "Available years: [2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
            "Total races available: 201\n",
            "Coverage: 9/9 years (100.0%)\n"
          ]
        }
      ],
      "source": [
        "# Import fastf1 first (make sure you ran the installation cell above!)\n",
        "import fastf1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Test FastF1 data availability for our target years\n",
        "test_years = [2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
        "coverage_results = []\n",
        "\n",
        "print(\"üîç Testing FastF1 data coverage for 2017-2025:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for year in test_years:\n",
        "    try:\n",
        "        # Try to get the season schedule\n",
        "        schedule = fastf1.get_event_schedule(year)\n",
        "        race_count = len(schedule)\n",
        "        coverage_results.append({\n",
        "            'year': year,\n",
        "            'available': True,\n",
        "            'race_count': race_count,\n",
        "            'first_race': schedule.iloc[0]['EventName'] if race_count > 0 else 'N/A',\n",
        "            'status': '‚úÖ Available'\n",
        "        })\n",
        "        print(f\"{year}: ‚úÖ Available - {race_count} races (First: {schedule.iloc[0]['EventName']})\")\n",
        "    except Exception as e:\n",
        "        coverage_results.append({\n",
        "            'year': year,\n",
        "            'available': False,\n",
        "            'race_count': 0,\n",
        "            'first_race': 'N/A',\n",
        "            'status': f'‚ùå Not Available: {str(e)[:50]}...'\n",
        "        })\n",
        "        print(f\"{year}: ‚ùå Not Available - {str(e)[:50]}...\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "coverage_df = pd.DataFrame(coverage_results)\n",
        "print(f\"\\nüìä Coverage Summary:\")\n",
        "print(f\"Available years: {coverage_df[coverage_df['available']]['year'].tolist()}\")\n",
        "print(f\"Total races available: {coverage_df[coverage_df['available']]['race_count'].sum()}\")\n",
        "print(f\"Coverage: {len(coverage_df[coverage_df['available']])}/{len(test_years)} years ({len(coverage_df[coverage_df['available']])/len(test_years)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÅ Sample Race Data Exploration\n",
        "\n",
        "Let's explore what data we can get from a recent race to understand the available features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "core           INFO \tLoading data for Bahrain Grand Prix - Race [v3.6.1]\n",
            "req            INFO \tUsing cached data for session_info\n",
            "req            INFO \tUsing cached data for driver_info\n",
            "req            INFO \tUsing cached data for session_status_data\n",
            "req            INFO \tUsing cached data for lap_count\n",
            "req            INFO \tUsing cached data for track_status_data\n",
            "req            INFO \tUsing cached data for _extended_timing_data\n",
            "req            INFO \tUsing cached data for timing_app_data\n",
            "core           INFO \tProcessing timing data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Loading 2024 Bahrain Grand Prix data...\n",
            "This may take a few minutes for first load...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "req            INFO \tUsing cached data for car_data\n",
            "req            INFO \tUsing cached data for position_data\n",
            "req            INFO \tUsing cached data for weather_data\n",
            "req            INFO \tUsing cached data for race_control_messages\n",
            "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '55', '16', '63', '4', '44', '81', '14', '18', '24', '20', '3', '22', '23', '27', '31', '10', '77', '2']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Session loaded successfully:\n",
            "   üìÖ Date: 2024-03-02 15:00:00\n",
            "   üèÅ Event: Bahrain Grand Prix\n",
            "   üìç Location: Sakhir\n",
            "   üå°Ô∏è Air Temp: 17.7¬∞C\n",
            "   üåßÔ∏è Rainfall: No\n"
          ]
        }
      ],
      "source": [
        "# Load a sample race to explore available data\n",
        "# Let's use 2024 Bahrain Grand Prix as an example\n",
        "try:\n",
        "    print(\"üîÑ Loading 2024 Bahrain Grand Prix data...\")\n",
        "    print(\"This may take a few minutes for first load...\")\n",
        "    \n",
        "    # Load race session\n",
        "    session = fastf1.get_session(2024, 'Bahrain', 'R')  # 'R' for Race\n",
        "    session.load()\n",
        "    \n",
        "    print(f\"‚úÖ Session loaded successfully:\")\n",
        "    print(f\"   üìÖ Date: {session.date}\")\n",
        "    print(f\"   üèÅ Event: {session.event['EventName']}\")\n",
        "    print(f\"   üìç Location: {session.event['Location']}\")\n",
        "    \n",
        "    # Weather info with proper handling\n",
        "    if len(session.weather_data) > 0:\n",
        "        air_temp = session.weather_data['AirTemp'].iloc[-1]\n",
        "        rainfall = session.weather_data['Rainfall'].any()\n",
        "        print(f\"   üå°Ô∏è Air Temp: {air_temp}¬∞C\")\n",
        "        print(f\"   üåßÔ∏è Rainfall: {'Yes' if rainfall else 'No'}\")\n",
        "    else:\n",
        "        print(\"   üå°Ô∏è Air Temp: N/A\")\n",
        "        print(\"   üåßÔ∏è Rainfall: N/A\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading race data: {e}\")\n",
        "    print(\"Trying alternative race...\")\n",
        "    \n",
        "    try:\n",
        "        # Fallback to 2023 data\n",
        "        session = fastf1.get_session(2023, 'Bahrain', 'R')\n",
        "        session.load()\n",
        "        print(f\"‚úÖ Fallback session loaded: {session.event['EventName']} 2023\")\n",
        "    except Exception as e2:\n",
        "        print(f\"‚ùå Fallback also failed: {e2}\")\n",
        "        session = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç AVAILABLE DATA STRUCTURES:\n",
            "==================================================\n",
            "\n",
            "üìä RACE RESULTS:\n",
            "   Shape: (20, 22)\n",
            "   Columns: ['DriverNumber', 'BroadcastName', 'Abbreviation', 'DriverId', 'TeamName', 'TeamColor', 'TeamId', 'FirstName', 'LastName', 'FullName', 'HeadshotUrl', 'CountryCode', 'Position', 'ClassifiedPosition', 'GridPosition', 'Q1', 'Q2', 'Q3', 'Time', 'Status', 'Points', 'Laps']\n",
            "   Sample (Top 5):\n",
            "    Position Abbreviation DriverNumber         TeamName  \\\n",
            "1        1.0          VER            1  Red Bull Racing   \n",
            "11       2.0          PER           11  Red Bull Racing   \n",
            "55       3.0          SAI           55          Ferrari   \n",
            "16       4.0          LEC           16          Ferrari   \n",
            "63       5.0          RUS           63         Mercedes   \n",
            "\n",
            "                     Time    Status  \n",
            "1  0 days 01:31:44.742000  Finished  \n",
            "11 0 days 00:00:22.457000  Finished  \n",
            "55 0 days 00:00:25.110000  Finished  \n",
            "16 0 days 00:00:39.669000  Finished  \n",
            "63 0 days 00:00:46.788000  Finished  \n",
            "\n",
            "‚è±Ô∏è LAP DATA:\n",
            "   Shape: (1129, 31)\n",
            "   Total laps: 57.0\n",
            "   Columns: ['Time', 'Driver', 'DriverNumber', 'LapTime', 'LapNumber', 'Stint', 'PitOutTime', 'PitInTime', 'Sector1Time', 'Sector2Time']...\n",
            "   üèÜ Fastest Lap: VER - 0 days 00:01:32.608000\n",
            "\n",
            "üå§Ô∏è WEATHER DATA:\n",
            "   Shape: (157, 8)\n",
            "   Columns: ['Time', 'AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed']\n",
            "   Temperature range: 17.6¬∞C - 18.9¬∞C\n",
            "   Track temp range: 21.9¬∞C - 26.5¬∞C\n",
            "\n",
            "üö¶ TRACK STATUS:\n",
            "   Shape: (7, 3)\n",
            "   Status changes: 2\n",
            "   Unique statuses: ['1' '2']\n"
          ]
        }
      ],
      "source": [
        "# Explore available data structures if session loaded successfully\n",
        "if session is not None:\n",
        "    print(\"üîç AVAILABLE DATA STRUCTURES:\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # 1. Results data\n",
        "    if hasattr(session, 'results') and len(session.results) > 0:\n",
        "        print(f\"\\nüìä RACE RESULTS:\")\n",
        "        print(f\"   Shape: {session.results.shape}\")\n",
        "        print(f\"   Columns: {list(session.results.columns)}\")\n",
        "        print(f\"   Sample (Top 5):\")\n",
        "        display_cols = ['Position', 'Abbreviation', 'DriverNumber', 'TeamName', 'Time', 'Status']\n",
        "        available_display_cols = [col for col in display_cols if col in session.results.columns]\n",
        "        print(session.results[available_display_cols].head())\n",
        "    \n",
        "    # 2. Laps data\n",
        "    if hasattr(session, 'laps') and len(session.laps) > 0:\n",
        "        print(f\"\\n‚è±Ô∏è LAP DATA:\")\n",
        "        print(f\"   Shape: {session.laps.shape}\")\n",
        "        print(f\"   Total laps: {session.laps['LapNumber'].max()}\")\n",
        "        print(f\"   Columns: {list(session.laps.columns)[:10]}...\")  # Show first 10 columns\n",
        "        \n",
        "        # Sample fastest lap\n",
        "        fastest_lap = session.laps.pick_fastest()\n",
        "        if fastest_lap is not None:\n",
        "            print(f\"   üèÜ Fastest Lap: {fastest_lap['Driver']} - {fastest_lap['LapTime']}\")\n",
        "    \n",
        "    # 3. Weather data\n",
        "    if hasattr(session, 'weather_data') and len(session.weather_data) > 0:\n",
        "        print(f\"\\nüå§Ô∏è WEATHER DATA:\")\n",
        "        print(f\"   Shape: {session.weather_data.shape}\")\n",
        "        print(f\"   Columns: {list(session.weather_data.columns)}\")\n",
        "        print(f\"   Temperature range: {session.weather_data['AirTemp'].min():.1f}¬∞C - {session.weather_data['AirTemp'].max():.1f}¬∞C\")\n",
        "        print(f\"   Track temp range: {session.weather_data['TrackTemp'].min():.1f}¬∞C - {session.weather_data['TrackTemp'].max():.1f}¬∞C\")\n",
        "    \n",
        "    # 4. Track status\n",
        "    if hasattr(session, 'track_status') and len(session.track_status) > 0:\n",
        "        print(f\"\\nüö¶ TRACK STATUS:\")\n",
        "        print(f\"   Shape: {session.track_status.shape}\")\n",
        "        print(f\"   Status changes: {session.track_status['Status'].nunique()}\")\n",
        "        print(f\"   Unique statuses: {session.track_status['Status'].unique()}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No session data available for detailed exploration\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèéÔ∏è Driver Telemetry Analysis\n",
        "\n",
        "Let's dive deeper into telemetry data for individual drivers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç DRIVER TELEMETRY EXPLORATION:\n",
            "==================================================\n",
            "üìã Available drivers: ['VER', 'PER', 'SAI', 'LEC', 'RUS', 'NOR', 'HAM', 'PIA', 'ALO', 'STR'] ...\n",
            "\n",
            "üéØ Analyzing driver: VER\n",
            "   Total laps: 57\n",
            "   üèÅ Lap Times:\n",
            "      Fastest: 0 days 00:01:32.608000\n",
            "      Average: 0 days 00:01:36.574421052\n",
            "      Slowest: 0 days 00:01:57.854000\n",
            "   üèÅ Sector Times (Available: ['Sector1Time', 'Sector2Time', 'Sector3Time']):\n",
            "      Sector1Time: 0 days 00:00:29.741000 (best) - 0 days 00:00:31.408017857 (avg)\n",
            "      Sector2Time: 0 days 00:00:39.916000 (best) - 0 days 00:00:41.414842105 (avg)\n",
            "      Sector3Time: 0 days 00:00:22.951000 (best) - 0 days 00:00:23.734122807 (avg)\n",
            "   üèéÔ∏è Tire Compounds Used:\n",
            "      SOFT: 37 laps\n",
            "      HARD: 20 laps\n"
          ]
        }
      ],
      "source": [
        "# Explore telemetry data for specific drivers\n",
        "if session is not None and hasattr(session, 'laps') and len(session.laps) > 0:\n",
        "    print(\"üîç DRIVER TELEMETRY EXPLORATION:\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Get unique drivers\n",
        "    drivers = session.laps['Driver'].unique()\n",
        "    print(f\"üìã Available drivers: {list(drivers[:10])}{' ...' if len(drivers) > 10 else ''}\")\n",
        "    \n",
        "    # Focus on a specific driver (e.g., VER for Verstappen)\n",
        "    if 'VER' in drivers:\n",
        "        target_driver = 'VER'\n",
        "    elif len(drivers) > 0:\n",
        "        target_driver = drivers[0]\n",
        "    else:\n",
        "        target_driver = None\n",
        "    \n",
        "    if target_driver:\n",
        "        print(f\"\\nüéØ Analyzing driver: {target_driver}\")\n",
        "        \n",
        "        # Get driver's laps\n",
        "        driver_laps = session.laps.pick_driver(target_driver)\n",
        "        print(f\"   Total laps: {len(driver_laps)}\")\n",
        "        \n",
        "        if len(driver_laps) > 0:\n",
        "            # Lap time analysis\n",
        "            print(f\"   üèÅ Lap Times:\")\n",
        "            valid_laps = driver_laps.dropna(subset=['LapTime'])\n",
        "            if len(valid_laps) > 0:\n",
        "                print(f\"      Fastest: {valid_laps['LapTime'].min()}\")\n",
        "                print(f\"      Average: {valid_laps['LapTime'].mean()}\")\n",
        "                print(f\"      Slowest: {valid_laps['LapTime'].max()}\")\n",
        "            \n",
        "            # Sector times analysis\n",
        "            sector_cols = ['Sector1Time', 'Sector2Time', 'Sector3Time']\n",
        "            available_sectors = [col for col in sector_cols if col in driver_laps.columns]\n",
        "            \n",
        "            if available_sectors:\n",
        "                print(f\"   üèÅ Sector Times (Available: {available_sectors}):\")\n",
        "                for sector in available_sectors:\n",
        "                    sector_data = driver_laps[sector].dropna()\n",
        "                    if len(sector_data) > 0:\n",
        "                        print(f\"      {sector}: {sector_data.min()} (best) - {sector_data.mean()} (avg)\")\n",
        "            \n",
        "            # Tire compound usage\n",
        "            if 'Compound' in driver_laps.columns:\n",
        "                compounds = driver_laps['Compound'].value_counts()\n",
        "                print(f\"   üèéÔ∏è Tire Compounds Used:\")\n",
        "                for compound, count in compounds.items():\n",
        "                    print(f\"      {compound}: {count} laps\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No lap data available for telemetry analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç FastF1 Extracted Data Analysis\n",
        "\n",
        "Let's analyze the FastF1 features we've extracted for 2017-2025 to understand data quality and coverage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä FASTF1 COMPLETE DATASET ANALYSIS:\n",
            "============================================================\n",
            "üìÅ Dataset Overview:\n",
            "   Shape: (2415, 29)\n",
            "   Columns: 29\n",
            "   Records: 2415 driver-race entries\n",
            "\n",
            "üìÖ Year Coverage:\n",
            "   2018: 420 records (~21 races)\n",
            "   2019: 340 records (~17 races)\n",
            "   2020: 340 records (~17 races)\n",
            "   2021: 379 records (~18 races)\n",
            "   2022: 198 records (~9 races)\n",
            "   2023: 299 records (~14 races)\n",
            "   2024: 359 records (~17 races)\n",
            "   2025: 80 records (~4 races)\n",
            "\n",
            "üèéÔ∏è Driver Coverage:\n",
            "   Total unique drivers: 43\n",
            "   Top drivers by records:\n",
            "      VER: 121 races\n",
            "      GAS: 121 races\n",
            "      LEC: 121 races\n",
            "      HAM: 120 races\n",
            "      SAI: 120 races\n",
            "      STR: 119 races\n",
            "      BOT: 117 races\n",
            "      PER: 115 races\n",
            "      RIC: 103 races\n",
            "      OCO: 103 races\n",
            "\n",
            "üéØ Feature Completeness Analysis:\n",
            "   Feature completeness rates:\n",
            "      driver_number: 100.0% complete (0 missing)\n",
            "      position: 100.0% complete (0 missing)\n",
            "      grid_position: 100.0% complete (0 missing)\n",
            "      points: 100.0% complete (0 missing)\n",
            "      status: 100.0% complete (0 missing)\n",
            "      fastest_lap_time: 97.6% complete (57 missing)\n",
            "      avg_lap_time: 97.6% complete (57 missing)\n",
            "      lap_time_std: 96.1% complete (94 missing)\n",
            "      total_laps: 100.0% complete (0 missing)\n",
            "      avg_sector1_time: 97.0% complete (72 missing)\n",
            "      avg_sector2_time: 97.6% complete (57 missing)\n",
            "      avg_sector3_time: 97.6% complete (57 missing)\n",
            "      max_speed: 97.6% complete (57 missing)\n",
            "      avg_speed: 97.6% complete (57 missing)\n",
            "      speed_variance: 97.0% complete (72 missing)\n",
            "\n",
            "üîç Sample Data Quality Check:\n",
            "   Sample record: 2018 Australian Grand Prix - VET\n",
            "   Sector 1: 30.737s\n",
            "   Main Compound: SOFT\n",
            "   Air Temp: nan¬∞C\n",
            "   Track Temp: nan¬∞C\n",
            "   Max Speed: 278.0 km/h\n"
          ]
        }
      ],
      "source": [
        "# Load and analyze the complete FastF1 dataset\n",
        "print(\"üìä FASTF1 COMPLETE DATASET ANALYSIS:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load the complete FastF1 features (NEW COMPLETE DATA - 2018-2025!)\n",
        "fastf1_complete = pd.read_csv(RAW_DATA_DIR / 'fastf1_features_2018_2025_complete.csv')\n",
        "\n",
        "print(f\"üìÅ Dataset Overview:\")\n",
        "print(f\"   Shape: {fastf1_complete.shape}\")\n",
        "print(f\"   Columns: {len(fastf1_complete.columns)}\")\n",
        "print(f\"   Records: {len(fastf1_complete)} driver-race entries\")\n",
        "\n",
        "# Analyze year coverage\n",
        "year_analysis = fastf1_complete['year'].value_counts().sort_index()\n",
        "print(f\"\\nüìÖ Year Coverage:\")\n",
        "for year, count in year_analysis.items():\n",
        "    races_approx = count // 20  # Assuming ~20 drivers per race\n",
        "    print(f\"   {year}: {count} records (~{races_approx} races)\")\n",
        "\n",
        "print(f\"\\nüèéÔ∏è Driver Coverage:\")\n",
        "driver_counts = fastf1_complete['driver_abbreviation'].value_counts()\n",
        "print(f\"   Total unique drivers: {len(driver_counts)}\")\n",
        "print(f\"   Top drivers by records:\")\n",
        "for driver, count in driver_counts.head(10).items():\n",
        "    print(f\"      {driver}: {count} races\")\n",
        "\n",
        "# Analyze feature completeness\n",
        "print(f\"\\nüéØ Feature Completeness Analysis:\")\n",
        "feature_cols = [col for col in fastf1_complete.columns if col not in \n",
        "               ['year', 'race_name', 'date', 'circuit_name', 'event_name', 'driver_abbreviation', 'round']]\n",
        "\n",
        "missing_analysis = {}\n",
        "for col in feature_cols[:15]:  # Analyze first 15 features\n",
        "    missing_count = fastf1_complete[col].isna().sum()\n",
        "    completeness = ((len(fastf1_complete) - missing_count) / len(fastf1_complete)) * 100\n",
        "    missing_analysis[col] = {\n",
        "        'missing': missing_count,\n",
        "        'completeness': completeness\n",
        "    }\n",
        "\n",
        "print(f\"   Feature completeness rates:\")\n",
        "for feature, stats in missing_analysis.items():\n",
        "    print(f\"      {feature}: {stats['completeness']:.1f}% complete ({stats['missing']} missing)\")\n",
        "\n",
        "print(f\"\\nüîç Sample Data Quality Check:\")\n",
        "# Check a sample record with data\n",
        "sample_with_data = fastf1_complete[fastf1_complete['avg_sector1_time'].notna()]\n",
        "if len(sample_with_data) > 0:\n",
        "    sample = sample_with_data.iloc[0]\n",
        "    print(f\"   Sample record: {sample['year']} {sample['race_name']} - {sample['driver_abbreviation']}\")\n",
        "    print(f\"   Sector 1: {sample['avg_sector1_time']:.3f}s\")\n",
        "    print(f\"   Main Compound: {sample['main_compound']}\")\n",
        "    print(f\"   Air Temp: {sample['air_temp']:.1f}¬∞C\")\n",
        "    print(f\"   Track Temp: {sample['track_temp']:.1f}¬∞C\")\n",
        "    print(f\"   Max Speed: {sample['max_speed']:.1f} km/h\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è No records with sector time data found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è DATA QUALITY ISSUES ANALYSIS:\n",
            "==================================================\n",
            "üìä Critical Missing Data:\n",
            "   Records with NO sector time data: 57/2415 (2.4%)\n",
            "\n",
            "üìÖ Missing Data by Year:\n",
            "   2018: 16/420 missing (3.8%)\n",
            "   2019: 2/340 missing (0.6%)\n",
            "   2020: 9/340 missing (2.6%)\n",
            "   2021: 10/379 missing (2.6%)\n",
            "   2022: 3/198 missing (1.5%)\n",
            "   2023: 3/299 missing (1.0%)\n",
            "   2024: 10/359 missing (2.8%)\n",
            "   2025: 4/80 missing (5.0%)\n",
            "\n",
            "üéØ Most Problematic Features:\n",
            "   ‚úÖ No severely problematic features found\n",
            "\n",
            "üîç Data Consistency Checks:\n",
            "   Realistic sector times: 2087/2343 records\n",
            "   Tire compound variety: ['SOFT', 'SUPERSOFT', 'ULTRASOFT', 'MEDIUM', 'HYPERSOFT', 'HARD', 'INTERMEDIATE', 'WET', 'UNKNOWN']\n",
            "\n",
            "üìù DATA QUALITY SUMMARY:\n",
            "   ‚Ä¢ Total records: 2415\n",
            "   ‚Ä¢ Years covered: 2018-2025\n",
            "   ‚Ä¢ Unique drivers: 43\n",
            "   ‚Ä¢ Complete telemetry records: 2358\n",
            "   ‚Ä¢ Data completeness: 97.6%\n"
          ]
        }
      ],
      "source": [
        "# Data Quality Issues Analysis\n",
        "print(\"‚ö†Ô∏è DATA QUALITY ISSUES ANALYSIS:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check for missing sector times (critical features)\n",
        "sector_missing = fastf1_complete[['avg_sector1_time', 'avg_sector2_time', 'avg_sector3_time']].isna().all(axis=1).sum()\n",
        "print(f\"üìä Critical Missing Data:\")\n",
        "print(f\"   Records with NO sector time data: {sector_missing}/{len(fastf1_complete)} ({sector_missing/len(fastf1_complete)*100:.1f}%)\")\n",
        "\n",
        "# Analyze by year - which years have more missing data?\n",
        "print(f\"\\nüìÖ Missing Data by Year:\")\n",
        "for year in sorted(fastf1_complete['year'].unique()):\n",
        "    year_data = fastf1_complete[fastf1_complete['year'] == year]\n",
        "    year_missing = year_data[['avg_sector1_time', 'avg_sector2_time', 'avg_sector3_time']].isna().all(axis=1).sum()\n",
        "    print(f\"   {year}: {year_missing}/{len(year_data)} missing ({year_missing/len(year_data)*100:.1f}%)\")\n",
        "\n",
        "# Analyze which features have the most issues\n",
        "print(f\"\\nüéØ Most Problematic Features:\")\n",
        "problematic_features = []\n",
        "for feature, stats in missing_analysis.items():\n",
        "    if stats['completeness'] < 50:  # Less than 50% complete\n",
        "        problematic_features.append((feature, stats['completeness']))\n",
        "\n",
        "if problematic_features:\n",
        "    problematic_features.sort(key=lambda x: x[1])\n",
        "    for feature, completeness in problematic_features:\n",
        "        print(f\"   {feature}: {completeness:.1f}% complete\")\n",
        "else:\n",
        "    print(\"   ‚úÖ No severely problematic features found\")\n",
        "\n",
        "# Check data consistency\n",
        "print(f\"\\nüîç Data Consistency Checks:\")\n",
        "\n",
        "# Check if we have realistic sector times\n",
        "if len(sample_with_data) > 0:\n",
        "    realistic_sectors = sample_with_data[\n",
        "        (sample_with_data['avg_sector1_time'] > 20) & \n",
        "        (sample_with_data['avg_sector1_time'] < 60)\n",
        "    ]\n",
        "    print(f\"   Realistic sector times: {len(realistic_sectors)}/{len(sample_with_data)} records\")\n",
        "    \n",
        "    # Check tire compound variety\n",
        "    compounds = fastf1_complete['main_compound'].dropna().unique()\n",
        "    print(f\"   Tire compound variety: {list(compounds)}\")\n",
        "    \n",
        "    # Check temperature ranges\n",
        "    if 'air_temp' in fastf1_complete.columns:\n",
        "        temp_data = fastf1_complete['air_temp'].dropna()\n",
        "        if len(temp_data) > 0:\n",
        "            print(f\"   Air temperature range: {temp_data.min():.1f}¬∞C - {temp_data.max():.1f}¬∞C\")\n",
        "    \n",
        "    if 'track_temp' in fastf1_complete.columns:\n",
        "        track_temp_data = fastf1_complete['track_temp'].dropna()\n",
        "        if len(track_temp_data) > 0:\n",
        "            print(f\"   Track temperature range: {track_temp_data.min():.1f}¬∞C - {track_temp_data.max():.1f}¬∞C\")\n",
        "\n",
        "print(f\"\\nüìù DATA QUALITY SUMMARY:\")\n",
        "print(f\"   ‚Ä¢ Total records: {len(fastf1_complete)}\")\n",
        "print(f\"   ‚Ä¢ Years covered: {fastf1_complete['year'].min()}-{fastf1_complete['year'].max()}\")\n",
        "print(f\"   ‚Ä¢ Unique drivers: {fastf1_complete['driver_abbreviation'].nunique()}\")\n",
        "print(f\"   ‚Ä¢ Complete telemetry records: {len(fastf1_complete) - sector_missing}\")\n",
        "print(f\"   ‚Ä¢ Data completeness: {((len(fastf1_complete) - sector_missing)/len(fastf1_complete)*100):.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó INTEGRATION COMPATIBILITY ANALYSIS:\n",
            "=======================================================\n",
            "üìä Dataset Comparison:\n",
            "   Ergast records: 3718\n",
            "   FastF1 records: 2415\n",
            "   Overlap potential: 2415 records\n",
            "\n",
            "üìÖ Year Overlap Analysis:\n",
            "   Ergast years: [np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
            "   FastF1 years: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
            "   Overlapping years: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)] (8 years)\n",
            "\n",
            "üèéÔ∏è Driver Mapping Analysis:\n",
            "   FastF1 drivers: 43 unique\n",
            "   Ergast drivers: 48 unique\n",
            "   Mappable drivers: 24/43 (55.8%)\n",
            "   Unmappable drivers: ['AIT', 'ANT', 'BEA', 'BOR', 'COL', 'DEV', 'DOO', 'ERI', 'FIT', 'GIO', 'GRO', 'HAD', 'HAR', 'KUB', 'KVY', 'LAW', 'SAR', 'SIR', 'VAN']\n",
            "\n",
            "üìà Integration Potential:\n",
            "   FastF1 records with mappable drivers: 2097\n",
            "   Potential enhanced records: 2097 with FastF1 features\n",
            "   Original Ergast features: 43\n",
            "   New FastF1 features: 22\n",
            "   Total enhanced features: 65\n",
            "\n",
            "üéØ INTEGRATION RECOMMENDATION:\n",
            "   ‚úÖ GOOD - 56.4% of Ergast data can be enhanced\n",
            "   üìä Recommended: Proceed with integration\n",
            "\n",
            "üìã Next Steps for Integration:\n",
            "   1. Improve driver abbreviation mapping (add missing drivers)\n",
            "   2. Handle missing FastF1 data (imputation or exclusion strategy)\n",
            "   3. Align race/round matching for precise merging\n",
            "   4. Decide on feature selection (which FastF1 features to keep)\n",
            "   5. Create final integrated dataset for model training\n"
          ]
        }
      ],
      "source": [
        "# Integration Compatibility Analysis with Ergast Data\n",
        "print(\"üîó INTEGRATION COMPATIBILITY ANALYSIS:\")\n",
        "print(\"=\"*55)\n",
        "\n",
        "# Load existing Ergast dataset for comparison\n",
        "ergast_df = pd.read_csv(PROCESSED_DATA_DIR / 'f1_race_prediction_dataset.csv')\n",
        "\n",
        "print(f\"üìä Dataset Comparison:\")\n",
        "print(f\"   Ergast records: {len(ergast_df)}\")\n",
        "print(f\"   FastF1 records: {len(fastf1_complete)}\")\n",
        "print(f\"   Overlap potential: {min(len(ergast_df), len(fastf1_complete))} records\")\n",
        "\n",
        "# Check year overlap\n",
        "ergast_years = set(ergast_df['year'].unique())\n",
        "fastf1_years = set(fastf1_complete['year'].unique())\n",
        "overlap_years = ergast_years.intersection(fastf1_years)\n",
        "\n",
        "print(f\"\\nüìÖ Year Overlap Analysis:\")\n",
        "print(f\"   Ergast years: {sorted(ergast_years)}\")\n",
        "print(f\"   FastF1 years: {sorted(fastf1_years)}\")\n",
        "print(f\"   Overlapping years: {sorted(overlap_years)} ({len(overlap_years)} years)\")\n",
        "\n",
        "# Driver mapping analysis\n",
        "print(f\"\\nüèéÔ∏è Driver Mapping Analysis:\")\n",
        "\n",
        "# Create basic driver mapping\n",
        "driver_mapping = {\n",
        "    'VER': 'max_verstappen', 'HAM': 'hamilton', 'BOT': 'bottas', 'RUS': 'russell',\n",
        "    'NOR': 'norris', 'PER': 'perez', 'SAI': 'sainz', 'LEC': 'leclerc',\n",
        "    'ALO': 'alonso', 'STR': 'stroll', 'VET': 'vettel', 'RAI': 'raikkonen',\n",
        "    'RIC': 'ricciardo', 'OCO': 'ocon', 'GAS': 'gasly', 'TSU': 'tsunoda',\n",
        "    'ALB': 'albon', 'LAT': 'latifi', 'MSC': 'mick_schumacher', 'MAZ': 'mazepin',\n",
        "    'HUL': 'hulkenberg', 'MAG': 'kevin_magnussen', 'ZHO': 'zhou', 'PIA': 'piastri'\n",
        "}\n",
        "\n",
        "fastf1_drivers = set(fastf1_complete['driver_abbreviation'].unique())\n",
        "ergast_drivers = set(ergast_df['driver_id'].unique())\n",
        "mappable_drivers = set(driver_mapping.keys()).intersection(fastf1_drivers)\n",
        "\n",
        "print(f\"   FastF1 drivers: {len(fastf1_drivers)} unique\")\n",
        "print(f\"   Ergast drivers: {len(ergast_drivers)} unique\") \n",
        "print(f\"   Mappable drivers: {len(mappable_drivers)}/{len(fastf1_drivers)} ({len(mappable_drivers)/len(fastf1_drivers)*100:.1f}%)\")\n",
        "\n",
        "unmappable = fastf1_drivers - set(driver_mapping.keys())\n",
        "if unmappable:\n",
        "    print(f\"   Unmappable drivers: {sorted(unmappable)}\")\n",
        "\n",
        "# Calculate potential merged dataset size\n",
        "fastf1_with_mapping = fastf1_complete[fastf1_complete['driver_abbreviation'].isin(mappable_drivers)]\n",
        "print(f\"\\nüìà Integration Potential:\")\n",
        "print(f\"   FastF1 records with mappable drivers: {len(fastf1_with_mapping)}\")\n",
        "print(f\"   Potential enhanced records: {len(fastf1_with_mapping)} with FastF1 features\")\n",
        "print(f\"   Original Ergast features: {len(ergast_df.columns)}\")\n",
        "print(f\"   New FastF1 features: {len(feature_cols)}\")\n",
        "print(f\"   Total enhanced features: {len(ergast_df.columns) + len(feature_cols)}\")\n",
        "\n",
        "print(f\"\\nüéØ INTEGRATION RECOMMENDATION:\")\n",
        "integration_success_rate = len(fastf1_with_mapping) / len(ergast_df) * 100\n",
        "if integration_success_rate > 50:\n",
        "    print(f\"   ‚úÖ GOOD - {integration_success_rate:.1f}% of Ergast data can be enhanced\")\n",
        "    print(f\"   üìä Recommended: Proceed with integration\")\n",
        "elif integration_success_rate > 25:\n",
        "    print(f\"   ‚ö†Ô∏è MODERATE - {integration_success_rate:.1f}% of Ergast data can be enhanced\")\n",
        "    print(f\"   üìä Recommended: Improve driver mapping and proceed selectively\")\n",
        "else:\n",
        "    print(f\"   ‚ùå POOR - Only {integration_success_rate:.1f}% of Ergast data can be enhanced\")\n",
        "    print(f\"   üìä Recommended: Significant improvements needed before integration\")\n",
        "\n",
        "print(f\"\\nüìã Next Steps for Integration:\")\n",
        "print(f\"   1. Improve driver abbreviation mapping (add missing drivers)\")\n",
        "print(f\"   2. Handle missing FastF1 data (imputation or exclusion strategy)\")\n",
        "print(f\"   3. Align race/round matching for precise merging\")\n",
        "print(f\"   4. Decide on feature selection (which FastF1 features to keep)\")\n",
        "print(f\"   5. Create final integrated dataset for model training\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "racecast_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
